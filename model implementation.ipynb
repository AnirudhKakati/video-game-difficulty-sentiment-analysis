{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980f0f07-96ca-44ff-a3ff-b22a15b2e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "c3aa8461-98d1-46c1-b5a0-6029c3b9949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read in the our csv with new extracted features\n",
    "df=pd.read_csv(\"featured_reviews.csv\",parse_dates=[\"timestamp_created\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a9981-3500-4531-b222-53c6568169d6",
   "metadata": {},
   "source": [
    "We will try to model if we can predict if the review would be positive or negative based on the content of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "67718b01-30e8-412a-8105-5ef309c3720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define our features and target\n",
    "y = df['voted_up']\n",
    "X = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "fa7ac0ba-5ea3-4fed-a42d-f798662e2b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review'], df['voted_up'], test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bc2b2-1762-47ea-a4a5-751f082b4d9f",
   "metadata": {},
   "source": [
    "The BERT model (Bidirectional Encoder Representations from Transformers) is a pre-trained transformer-based language model designed to understand text context bidirectionally. We will leverage it for text classification by fine-tuning it on our dataset to predict whether a review was positive or negative (voted_up)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062dc2c5-577e-483a-91ea-6f9f43ec3954",
   "metadata": {},
   "source": [
    "Each review was: <br>\n",
    "<ul>\n",
    "    <li>Split into tokens</li>\n",
    "    <li>Converted into unique token IDs (input_ids)</li>\n",
    "    <li>Padded or truncated to a maximum length of 128 tokens</li>\n",
    "    <li>Generated an attention_mask to indicate which tokens should be attended to</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467c146-abb0-464d-a58d-f101d07bfd26",
   "metadata": {},
   "source": [
    "We created a ReviewDataset class to manage the tokenized inputs and corresponding labels. <br>\n",
    "The dataset was then split into training and testing sets (X_train, y_train, X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "87f1acef-bf9d-437d-b2c2-40e5177fdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ReviewDataset(X_train, y_train)\n",
    "test_dataset = ReviewDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "ae391355-c6d4-4301-9b8b-c8f16da94b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Data (First 5 Rows):\n",
      "                                                  review  voted_up\n",
      "1288                                    yeah pretty good         1\n",
      "31280  well thought made game complexity slowly build...         1\n",
      "39225                                          hyvä peli         1\n",
      "17598  god love game played bg3 need good play game l...         1\n",
      "31369                          1010 best game ive played         1\n"
     ]
    }
   ],
   "source": [
    "# raw data before transformation ->\n",
    "print(\"Original Train Data (First 5 Rows):\")\n",
    "raw_sample = pd.DataFrame({\n",
    "    'review': X_train.iloc[:5],\n",
    "    'voted_up': y_train.iloc[:5]\n",
    "})\n",
    "print(raw_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "d090dfb5-e6e4-4d33-b539-94b558b1b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Train Data (Tokenized):\n",
      "                                           input_ids  \\\n",
      "0  [101, 3398, 3492, 2204, 102, 0, 0, 0, 0, 0, 0,...   \n",
      "1  [101, 2092, 2245, 2081, 2208, 11619, 3254, 164...   \n",
      "2  [101, 1044, 2100, 3567, 21877, 3669, 102, 0, 0...   \n",
      "3  [101, 2643, 2293, 2208, 2209, 1038, 2290, 2509...   \n",
      "4  [101, 7886, 2692, 2190, 2208, 4921, 2063, 2209...   \n",
      "\n",
      "                                      attention_mask  label  \n",
      "0  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      1  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...      1  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...      1  \n"
     ]
    }
   ],
   "source": [
    "# Display transformed data (tokenized)\n",
    "def display_transformed_data(dataset, n=5):\n",
    "    \"\"\"\n",
    "    Function to display the transform review data (tokenized)\n",
    "    \"\"\"\n",
    "    print(\"\\nTransformed Train Data (Tokenized):\")\n",
    "    transformed_samples = []\n",
    "    for i in range(n):\n",
    "        sample = dataset[i]\n",
    "        transformed_samples.append({\n",
    "            'input_ids': sample['input_ids'].tolist(),\n",
    "            'attention_mask': sample['attention_mask'].tolist(),\n",
    "            'label': sample['label'].item()\n",
    "        })\n",
    "    transformed_df = pd.DataFrame(transformed_samples)\n",
    "    print(transformed_df)\n",
    "\n",
    "# first 5 samples from the transformed dataset ->\n",
    "display_transformed_data(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50cb619f-1c1f-4054-8b10-1c9c15e163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e32cd8-bffe-4b1b-a705-c1c0470aaa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for binary classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0412ccaf-30ad-4608-8e12-fc6da51b733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06c3b255-ba91-422b-956f-0386c42ab41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2058819322121209\n",
      "Epoch 2, Loss: 0.13247972990714788\n",
      "Epoch 3, Loss: 0.07910977544507167\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move data to GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5304adf9-caa8-4ab7-92b7-7fb5ac384695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934370613008891\n",
      "F1-Score: 0.9635785236642213\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       826\n",
      "           1       0.97      0.96      0.96      7722\n",
      "\n",
      "    accuracy                           0.93      8548\n",
      "   macro avg       0.81      0.82      0.82      8548\n",
      "weighted avg       0.94      0.93      0.94      8548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "y_preds = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, axis=1)\n",
    "        \n",
    "        y_preds.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_preds))\n",
    "print(\"F1-Score:\", f1_score(y_true, y_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86470fd5-15ad-4868-a766-c4970dd6f804",
   "metadata": {},
   "source": [
    "Text reviews (review) contain detailed feedback, but their raw form is difficult for machine learning models to interpret directly. By extracting a sentiment score, we provide a numerical representation of the review’s polarity, making it easier for the model to process.\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a pre-trained rule-based sentiment analysis tool from the NLTK library, designed to handle social media text and other short reviews. <br>\n",
    "It provides four sentiment scores for a given text:\n",
    "<ul>\n",
    "    <li>Positive: Proportion of positive words</li>\n",
    "    <li>Neutral: Proportion of neutral words</li>\n",
    "    <li>Negative: Proportion of negative words</li>\n",
    "    <li>Compound: A single aggregated score that represents the overall sentiment of the text</li>\n",
    "</ul>\n",
    "For each review in the review column, we applied sia.polarity_scores(x) to compute sentiment scores. We selected the compound score, which is a normalized value between -1 (most negative) and 1 (most positive). This value is stored as the new column “sentiment_score”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc38525f-d285-48d9-b903-8b94e0cb5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aniru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "b127e62c-743a-4d1f-89cf-e056b8ba2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis to each review\n",
    "df['sentiment_score'] = df['review'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "ff7a683a-9a69-4f65-99cd-3925c51387c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['review', 'review_length', 'sentiment_score']],  # Include all features\n",
    "    df['voted_up'], \n",
    "    test_size=0.2, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "fd774eed-43b3-4f19-b56d-12cb858c079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36847</th>\n",
       "      <td>best cod since og mw2 imho vastly underrated b...</td>\n",
       "      <td>115</td>\n",
       "      <td>0.8070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36953</th>\n",
       "      <td>n ghbfrtvfrewdw2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>game surprised thought would pretty slow much ...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.7876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>fun game</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42616</th>\n",
       "      <td>dota best ever game</td>\n",
       "      <td>19</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  review_length  \\\n",
       "36847  best cod since og mw2 imho vastly underrated b...            115   \n",
       "36953                                   n ghbfrtvfrewdw2             16   \n",
       "32947  game surprised thought would pretty slow much ...            135   \n",
       "28797                                           fun game              8   \n",
       "42616                                dota best ever game             19   \n",
       "\n",
       "       sentiment_score  \n",
       "36847           0.8070  \n",
       "36953           0.0000  \n",
       "32947           0.7876  \n",
       "28797           0.5106  \n",
       "42616           0.6369  "
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display raw data before transformation\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "d35cde54-aa07-4407-88ae-b57a2d4014ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to normalize\n",
    "numerical_cols = ['review_length', 'sentiment_score']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "8c8f54f0-a431-409e-a361-99e0e19b9bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24083</th>\n",
       "      <td>first review maybe 15 years platform felt ough...</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.969998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31917</th>\n",
       "      <td>great game lot think</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.812441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36458</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.785939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>really fun really cool</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.877144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>good</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.720186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  review_length  \\\n",
       "24083  first review maybe 15 years platform felt ough...       0.019130   \n",
       "31917                               great game lot think       0.002376   \n",
       "36458                                            perfect       0.000750   \n",
       "9535                              really fun really cool       0.002626   \n",
       "17997                                               good       0.000375   \n",
       "\n",
       "       sentiment_score  \n",
       "24083         0.969998  \n",
       "31917         0.812441  \n",
       "36458         0.785939  \n",
       "9535          0.877144  \n",
       "17997         0.720186  "
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b5dfc-b723-4b32-bc44-51c6f461fe48",
   "metadata": {},
   "source": [
    "Similar to the last model we created a custom Dataset class (ReviewDataset) to include:\n",
    "<ul>\n",
    "    <li>Text Features: Tokenized input IDs and attention masks</li>\n",
    "    <li>Numerical Features: Normalized review_length and sentiment_score</li>\n",
    "    <li>Labels: voted_up</li>\n",
    "</ul>\n",
    "The key difference is that the __getitem__ method was updated to return both numerical features and tokenized text features, making the dataset compatible with the combined BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60f5074f-b20c-483b-a68b-32880c883057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, numerical_features, labels):\n",
    "        self.texts = texts\n",
    "        self.numerical_features = numerical_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        num_features = torch.tensor(self.numerical_features.iloc[idx], dtype=torch.float)\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'numerical_features': num_features,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "818766d1-accb-4ddd-93a6-dec9e890fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ReviewDataset(\n",
    "    texts=X_train['review'],\n",
    "    numerical_features=X_train[numerical_cols],\n",
    "    labels=y_train\n",
    ")\n",
    "\n",
    "test_dataset = ReviewDataset(\n",
    "    texts=X_test['review'],\n",
    "    numerical_features=X_test[numerical_cols],\n",
    "    labels=y_test\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "091f0690-bbd8-4394-990b-632c113cd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768 + len(numerical_cols), 2)  # Adjusted for the number of numerical features\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerical_features):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  \n",
    "        combined = torch.cat((cls_output, numerical_features), dim=1)  # Concatenated with numerical features\n",
    "        logits = self.fc(self.dropout(combined))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20e11c01-38ca-43f6-940d-a903ecfa4e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_6700\\335967104.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  num_features = torch.tensor(self.numerical_features.iloc[idx], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.20206833520540718\n",
      "Epoch 2, Loss: 0.1320957051658507\n",
      "Epoch 3, Loss: 0.0781316688128422\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = CustomBERTModel(bert_model).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask, numerical_features)\n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff9bd84e-a71a-4682-8ae2-5fc83c7dbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_6700\\335967104.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  num_features = torch.tensor(self.numerical_features.iloc[idx], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66       866\n",
      "           1       0.96      0.97      0.96      7682\n",
      "\n",
      "    accuracy                           0.93      8548\n",
      "   macro avg       0.82      0.80      0.81      8548\n",
      "weighted avg       0.93      0.93      0.93      8548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_preds = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask, numerical_features)\n",
    "        preds = torch.argmax(logits, axis=1)\n",
    "        y_preds.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60d6fc-965e-4359-aeb2-104e915fa4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd734842-93b5-4070-9017-559eef4c79f0",
   "metadata": {},
   "source": [
    "We will now use a LightGBM classifier model to try to model the same relationship.\n",
    "\n",
    "The review data is transformed for it to work with our classifier model. The transformation involves converting raw review text into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency). This step allows text data to be represented numerically for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b000cf50-590f-4a3c-8023-7ad761afcfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['review_length', 'sentiment_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "48d317f6-d11b-461c-823c-6ae5ff09bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "8daa0809-9762-42ab-9092-4d42d6749280",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "3a9fd431-aa7c-4b90-b6a4-cb9d90bc5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['review', 'review_length', 'sentiment_score']],\n",
    "    df['voted_up'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "d72f71fb-e397-471d-a151-8319227117b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_numerical = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test_numerical = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Fit TF-IDF on training data and transform both train and test reviews\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['review'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['review'])\n",
    "\n",
    "# Combine TF-IDF and scaled numerical features\n",
    "import scipy\n",
    "X_train_combined = scipy.sparse.hstack((X_train_tfidf, X_train_numerical))\n",
    "X_test_combined = scipy.sparse.hstack((X_test_tfidf, X_test_numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "4aff7e12-771e-46ef-9362-416a71f6468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Transformed Data (First 5 Rows):\n",
      "   010   10  100  1000  10010  100ing      1010   11  110  1110  ...   на  \\\n",
      "0  0.0  0.0  0.0   0.0    0.0     0.0  0.000000  0.0  0.0   0.0  ...  0.0   \n",
      "1  0.0  0.0  0.0   0.0    0.0     0.0  0.000000  0.0  0.0   0.0  ...  0.0   \n",
      "2  0.0  0.0  0.0   0.0    0.0     0.0  0.000000  0.0  0.0   0.0  ...  0.0   \n",
      "3  0.0  0.0  0.0   0.0    0.0     0.0  0.000000  0.0  0.0   0.0  ...  0.0   \n",
      "4  0.0  0.0  0.0   0.0    0.0     0.0  0.530583  0.0  0.0   0.0  ...  0.0   \n",
      "\n",
      "    не   но  послушай   то   ты  что  ミxノ  ヽ_ヽ___   二つ  \n",
      "0  0.0  0.0       0.0  0.0  0.0  0.0  0.0     0.0  0.0  \n",
      "1  0.0  0.0       0.0  0.0  0.0  0.0  0.0     0.0  0.0  \n",
      "2  0.0  0.0       0.0  0.0  0.0  0.0  0.0     0.0  0.0  \n",
      "3  0.0  0.0       0.0  0.0  0.0  0.0  0.0     0.0  0.0  \n",
      "4  0.0  0.0       0.0  0.0  0.0  0.0  0.0     0.0  0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "# we display the transformed data ->\n",
    "tfidf_dense = pd.DataFrame(\n",
    "    X_train_tfidf[:5].toarray(), \n",
    "    columns=vectorizer.get_feature_names_out() \n",
    ")\n",
    "print(\"TF-IDF Transformed Data (First 5 Rows):\")\n",
    "print(tfidf_dense.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b1d2c06-32e3-4a83-9b14-9ac5643a530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30751, number of negative: 3438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106902\n",
      "[LightGBM] [Info] Number of data points in the train set: 34189, number of used features: 3048\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.77      0.52       826\n",
      "           1       0.97      0.87      0.92      7722\n",
      "\n",
      "    accuracy                           0.86      8548\n",
      "   macro avg       0.68      0.82      0.72      8548\n",
      "weighted avg       0.92      0.86      0.88      8548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1218: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(class_weight='balanced')\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_combined)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f490a1-a30a-4fe4-94b7-3adb1b495f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c668ca10-af9a-49f9-a17d-fd620a09c993",
   "metadata": {},
   "source": [
    "After training the model, we adjusted the decision threshold (default is 0.5) to optimize performance for different class priorities. We tested thresholds ranging from 0.1 to 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "070eec9d-47c7-4ff3-be87-5ece60dc4517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.25      0.38       826\n",
      "           1       0.93      0.99      0.96      7722\n",
      "\n",
      "    accuracy                           0.92      8548\n",
      "   macro avg       0.86      0.62      0.67      8548\n",
      "weighted avg       0.91      0.92      0.90      8548\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58       826\n",
      "           1       0.95      0.98      0.96      7722\n",
      "\n",
      "    accuracy                           0.93      8548\n",
      "   macro avg       0.82      0.74      0.77      8548\n",
      "weighted avg       0.92      0.93      0.92      8548\n",
      "\n",
      "Threshold: 0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58       826\n",
      "           1       0.96      0.95      0.95      7722\n",
      "\n",
      "    accuracy                           0.91      8548\n",
      "   macro avg       0.75      0.78      0.77      8548\n",
      "weighted avg       0.92      0.91      0.92      8548\n",
      "\n",
      "Threshold: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.71      0.56       826\n",
      "           1       0.97      0.91      0.94      7722\n",
      "\n",
      "    accuracy                           0.89      8548\n",
      "   macro avg       0.71      0.81      0.75      8548\n",
      "weighted avg       0.92      0.89      0.90      8548\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.77      0.52       826\n",
      "           1       0.97      0.87      0.92      7722\n",
      "\n",
      "    accuracy                           0.86      8548\n",
      "   macro avg       0.68      0.82      0.72      8548\n",
      "weighted avg       0.92      0.86      0.88      8548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1218: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.1, 0.6, 0.1):\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c41662-3ad7-44cb-b95a-71e339e88686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284cc675-03ed-42aa-b809-251611a2eaad",
   "metadata": {},
   "source": [
    "To improve the model’s performance, we conducted a Grid Search over a small parameter space to find the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87ccf36f-0fb7-4b68-a55e-0bc86c773930",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],         \n",
    "    'n_estimators': [100, 200],           \n",
    "    'max_depth': [3, 5],                  \n",
    "    'subsample': [0.8, 1.0],              \n",
    "    'colsample_bytree': [0.8, 1.0]        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ac0ade6-fdf0-44a1-8eba-546de4741c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[LightGBM] [Info] Number of positive: 30751, number of negative: 3438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106902\n",
      "[LightGBM] [Info] Number of data points in the train set: 34189, number of used features: 3048\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best F1-Score: 0.9089000849347499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(class_weight='balanced')\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Optimize for F1-score\n",
    "    cv=3,          # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1      # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94bd162b-dc3c-4366-86dc-27cbacd2cff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30751, number of negative: 3438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106902\n",
      "[LightGBM] [Info] Number of data points in the train set: 34189, number of used features: 3048\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.76      0.49       826\n",
      "           1       0.97      0.86      0.91      7722\n",
      "\n",
      "    accuracy                           0.85      8548\n",
      "   macro avg       0.67      0.81      0.70      8548\n",
      "weighted avg       0.91      0.85      0.87      8548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1218: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters\n",
    "best_params = grid_search.best_params_ \n",
    "\n",
    "# Retrain model with best parameters\n",
    "tuned_model = LGBMClassifier(**best_params, class_weight='balanced', random_state=42)\n",
    "tuned_model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = tuned_model.predict(X_test_combined)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab744af-6c67-4700-b7c1-4252308e65d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1de95f-a82c-4af0-be61-539564cbb398",
   "metadata": {},
   "source": [
    "We try to use an ensemble model with LightGBM, Logistic Regression and Naive Bayes for modelling the same relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1fb897f1-3122-4567-bc2e-b3a22b4483f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "384f678e-c8a5-4a43-b356-7e5b1198b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the base models of LightGBM, logistic regression and naive bayes\n",
    "base_models = [\n",
    "    ('lightgbm', LGBMClassifier(class_weight='balanced', random_state=42)),\n",
    "    ('logreg', LogisticRegression(max_iter=1000)),\n",
    "    ('nb', MultinomialNB())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d66bbe13-f93e-4883-945d-471e32f37c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression would be the meta model\n",
    "meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3e59cd01-f95f-4ebc-82b6-48d1632eaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=3 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e901d1a3-4b64-4dd1-ad19-2b228fcdbe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30751, number of negative: 3438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106902\n",
      "[LightGBM] [Info] Number of data points in the train set: 34189, number of used features: 3048\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 20500, number of negative: 2292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 71096\n",
      "[LightGBM] [Info] Number of data points in the train set: 22792, number of used features: 2273\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 20501, number of negative: 2292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 71038\n",
      "[LightGBM] [Info] Number of data points in the train set: 22793, number of used features: 2287\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 20501, number of negative: 2292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 70953\n",
      "[LightGBM] [Info] Number of data points in the train set: 22793, number of used features: 2289\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=3,\n",
       "                   estimators=[(&#x27;lightgbm&#x27;,\n",
       "                                LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                               random_state=42)),\n",
       "                               (&#x27;logreg&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                               (&#x27;nb&#x27;, MultinomialNB())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(cv=3,\n",
       "                   estimators=[(&#x27;lightgbm&#x27;,\n",
       "                                LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                               random_state=42)),\n",
       "                               (&#x27;logreg&#x27;, LogisticRegression(max_iter=1000)),\n",
       "                               (&#x27;nb&#x27;, MultinomialNB())],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lightgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>logreg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>nb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=3,\n",
       "                   estimators=[('lightgbm',\n",
       "                                LGBMClassifier(class_weight='balanced',\n",
       "                                               random_state=42)),\n",
       "                               ('logreg', LogisticRegression(max_iter=1000)),\n",
       "                               ('nb', MultinomialNB())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the ensemble model\n",
    "stacked_model.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "623600e4-ce72-4839-974b-1c84a306a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.51      0.60       826\n",
      "           1       0.95      0.98      0.96      7722\n",
      "\n",
      "    accuracy                           0.93      8548\n",
      "   macro avg       0.84      0.74      0.78      8548\n",
      "weighted avg       0.93      0.93      0.93      8548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1218: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacked_model.predict(X_test_combined)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a491ffd-19fb-4b1a-ab50-506e74baad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9215902-9346-4c0d-9825-2dc9eb9e8980",
   "metadata": {},
   "source": [
    "Next we make an ensemble model by bagging the LightGBM Classifier and try to model the same relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "efd7454f-e1da-47d7-881c-937ad481bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Parameters: {'max_features': 0.8, 'max_samples': 0.6, 'n_estimators': 5}\n",
      "Best F1-Score: 0.8950582797469929\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.71      0.55       826\n",
      "           1       0.97      0.91      0.94      7722\n",
      "\n",
      "    accuracy                           0.89      8548\n",
      "   macro avg       0.71      0.81      0.74      8548\n",
      "weighted avg       0.92      0.89      0.90      8548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the base LightGBM estimator\n",
    "base_estimator = LGBMClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=base_estimator,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10],          \n",
    "    'max_samples': [0.6, 0.8],       \n",
    "    'max_features': [0.6, 0.8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bagging_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted', \n",
    "    cv=3,                  \n",
    "    verbose=2,\n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_combined, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_combined)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127dfe3-ae0a-4eaf-a253-a5b015a87b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544d17b7-8443-4bed-bc5a-3957e6fd6d85",
   "metadata": {},
   "source": [
    "We will try to predict if a review mentions difficulty using review meta data like length and sentiment score. We will try to model review_length and sentiment_score to mentions_difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4964a141-cdcd-48ab-9c28-ef1db71c39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['game_name', 'review', 'voted_up', 'timestamp_created',\n",
       "       'author_num_games_owned', 'author_num_reviews',\n",
       "       'author_playtime_at_review', 'author_playtime_last_two_weeks',\n",
       "       'author_playtime_forever', 'review_length', 'difficulty_word_count',\n",
       "       'mentions_difficulty', 'roguelike', 'co_op', 'base_building',\n",
       "       'soulslike', 'deckbuilding', 'puzzle', 'metroidvania', 'rpg',\n",
       "       'competitive', 'first_person', 'crpg', 'multiplayer', 'action',\n",
       "       'sandbox', 'fantasy', 'simulation', 'platformer', 'shooter',\n",
       "       'open_world', 'strategy', 'survival', 'adventure', 'crafting',\n",
       "       'third_person', 'turn_based', '2d', 'experience_level_experienced',\n",
       "       'experience_level_intermediate', 'sentiment_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "8c7b3237-ab77-403d-8d9a-36ab587f3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take review_length and sentiment_score as our inputs and mentions_difficulty as our output\n",
    "features = [\n",
    "    'review_length', \n",
    "    'sentiment_score',   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "8d82e2e6-ee9d-4a6b-a1ff-e7a9648feca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df['mentions_difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "fa5bb1f6-e1b0-49e3-ae96-9a7d3c068619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.6597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_length  sentiment_score\n",
       "0            100           0.6369\n",
       "1              4           0.0000\n",
       "2             55           0.4215\n",
       "3             15           0.0000\n",
       "4             43          -0.6597"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "44538417-4afd-430a-ac21-30dd3e87b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "e6f44656-0f1a-4b12-b89e-c804815e9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both are numerical columns so we scale them\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "b64c1d46-4a2b-4820-a8f3-415b9fc7214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "import pandas as pd\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "1dc11b43-5f29-460a-ac03-d28e5da72f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033847</td>\n",
       "      <td>0.986899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.818441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.525776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.261613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.710736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29910</th>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.840392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29911</th>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.954048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29912</th>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.920096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29913</th>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.251313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29914</th>\n",
       "      <td>0.012742</td>\n",
       "      <td>0.972549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29915 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_length  sentiment_score\n",
       "0           0.033847         0.986899\n",
       "1           0.000398         0.818441\n",
       "2           0.002256         0.525776\n",
       "3           0.004380         0.261613\n",
       "4           0.000265         0.710736\n",
       "...              ...              ...\n",
       "29910       0.003186         0.840392\n",
       "29911       0.022564         0.954048\n",
       "29912       0.003584         0.920096\n",
       "29913       0.002787         0.251313\n",
       "29914       0.012742         0.972549\n",
       "\n",
       "[29915 rows x 2 columns]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "198ad592-1132-40bc-8978-3930a0e8152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentions_difficulty\n",
       "0    36788\n",
       "1     5949\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72355c-7ae1-40e9-b52a-4b3a6dd067bc",
   "metadata": {},
   "source": [
    "To combat unbalanced classes, we do sampling. We undersample the majority class and oversample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "e35d9b55-bc95-4f57-a837-8193530e6173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentions_difficulty\n",
       "0    20910\n",
       "1     4182\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy=0.2)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "049998c5-b67a-49b2-8eed-fe7316b6bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentions_difficulty\n",
       "0    20910\n",
       "1    20910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "627d4602-b522-41ea-a53a-1f943a52d98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-23 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-23 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-23 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-23 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-23 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-23 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-23 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-23 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-23 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-23 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-23 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a LightGBM model \n",
    "model = LGBMClassifier(class_weight='balanced')\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "8d6a15ae-1af9-499b-aec2-c2537cb793f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85     11028\n",
      "           1       0.34      0.73      0.46      1794\n",
      "\n",
      "    accuracy                           0.76     12822\n",
      "   macro avg       0.64      0.75      0.66     12822\n",
      "weighted avg       0.86      0.76      0.79     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "c10937c7-3cdd-4c90-8c17-8c4a2f887b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best F1-Score: 0.778229432215042\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85     11060\n",
      "           1       0.33      0.75      0.46      1762\n",
      "\n",
      "    accuracy                           0.76     12822\n",
      "   macro avg       0.64      0.76      0.65     12822\n",
      "weighted avg       0.87      0.76      0.79     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the same model but with some hyperparameter tuning\n",
    "model = LGBMClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],         \n",
    "    'max_depth': [3, 5],             \n",
    "    'learning_rate': [0.05, 0.1],     \n",
    "    'colsample_bytree': [0.8, 1.0],   \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,                   \n",
    "    verbose=2,\n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6373218-af69-4698-9721-96907539938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7288054-d22c-4a8e-8696-c2c9639f8d38",
   "metadata": {},
   "source": [
    "We will now use an XGBoost Classifier model to try to model the same relationship as the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "fe29a4e5-91e6-4203-bc7c-679462686c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:40:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best F1-Score: 0.7659379446556777\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76     11060\n",
      "           1       0.27      0.86      0.41      1762\n",
      "\n",
      "    accuracy                           0.66     12822\n",
      "   macro avg       0.62      0.75      0.59     12822\n",
      "weighted avg       0.87      0.66      0.71     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the base XGBoost model\n",
    "model = XGBClassifier(\n",
    "    scale_pos_weight=2,        # Adjust for class imbalance\n",
    "    use_label_encoder=False,  \n",
    "    eval_metric='logloss'    \n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],      \n",
    "    'learning_rate': [0.05, 0.1],   \n",
    "    'max_depth': [4, 6],            \n",
    "    'subsample': [0.8, 1.0],        \n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',    \n",
    "    cv=3,                     \n",
    "    verbose=2,               \n",
    "    n_jobs=-1                 \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fff46-392f-4c51-85be-8615bdb540a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "182bef53-5fbd-4d99-a84c-3cbe04a5ba30",
   "metadata": {},
   "source": [
    "We will now use an ensemble model of XGBoost, Logistic Regression and Naïve Bayes to model the same relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "ab587a75-7fb3-4041-ae59-eb89636b189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:43:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:43:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84     11060\n",
      "           1       0.33      0.73      0.45      1762\n",
      "\n",
      "    accuracy                           0.76     12822\n",
      "   macro avg       0.64      0.75      0.65     12822\n",
      "weighted avg       0.86      0.76      0.79     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=2,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "nb = GaussianNB()\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb), ('logreg', logreg), ('nb', nb)],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=3 \n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_model.predict(X_test_scaled)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "b6caf05c-9342-4589-b45f-99185527b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'xgb__n_estimators': [100, 150],     \n",
    "    'xgb__max_depth': [4, 6],            \n",
    "    'xgb__learning_rate': [0.05, 0.1],   \n",
    "    'final_estimator__C': [0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "08c1f511-2b1b-4747-aa59-39e3863d5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:56:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:56:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:56:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\aniru\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:56:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'final_estimator__C': 10, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 6, 'xgb__n_estimators': 150}\n",
      "Best Score: 0.7691706834535003\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.83     11028\n",
      "           1       0.32      0.74      0.45      1794\n",
      "\n",
      "    accuracy                           0.75     12822\n",
      "   macro avg       0.63      0.74      0.64     12822\n",
      "weighted avg       0.86      0.75      0.78     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=stacking_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  \n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04566de-d73b-4cf1-a59b-916145ce30d0",
   "metadata": {},
   "source": [
    "Thresholds between 0.3 and 0.9 were tested to improve performance metrics for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "98cd3841-09ab-4378-b144-52d1a974450e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.59      0.73     11028\n",
      "           1       0.25      0.86      0.39      1794\n",
      "\n",
      "    accuracy                           0.63     12822\n",
      "   macro avg       0.61      0.72      0.56     12822\n",
      "weighted avg       0.86      0.63      0.68     12822\n",
      "\n",
      "Threshold: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79     11028\n",
      "           1       0.29      0.79      0.42      1794\n",
      "\n",
      "    accuracy                           0.70     12822\n",
      "   macro avg       0.62      0.73      0.61     12822\n",
      "weighted avg       0.86      0.70      0.74     12822\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.83     11028\n",
      "           1       0.32      0.74      0.45      1794\n",
      "\n",
      "    accuracy                           0.75     12822\n",
      "   macro avg       0.63      0.74      0.64     12822\n",
      "weighted avg       0.86      0.75      0.78     12822\n",
      "\n",
      "Threshold: 0.6000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87     11028\n",
      "           1       0.37      0.66      0.48      1794\n",
      "\n",
      "    accuracy                           0.80     12822\n",
      "   macro avg       0.66      0.74      0.68     12822\n",
      "weighted avg       0.86      0.80      0.82     12822\n",
      "\n",
      "Threshold: 0.7000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91     11028\n",
      "           1       0.47      0.54      0.50      1794\n",
      "\n",
      "    accuracy                           0.85     12822\n",
      "   macro avg       0.70      0.72      0.71     12822\n",
      "weighted avg       0.86      0.85      0.85     12822\n",
      "\n",
      "Threshold: 0.8000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     11028\n",
      "           1       0.57      0.40      0.47      1794\n",
      "\n",
      "    accuracy                           0.87     12822\n",
      "   macro avg       0.74      0.68      0.70     12822\n",
      "weighted avg       0.86      0.87      0.86     12822\n",
      "\n",
      "Threshold: 0.9000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     11028\n",
      "           1       0.71      0.23      0.35      1794\n",
      "\n",
      "    accuracy                           0.88     12822\n",
      "   macro avg       0.80      0.61      0.64     12822\n",
      "weighted avg       0.86      0.88      0.85     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Adjust thresholds and evaluate\n",
    "for threshold in np.arange(0.3, 0.9, 0.1):\n",
    "    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1e8c0-f133-4a35-83af-53b70da95c98",
   "metadata": {},
   "source": [
    "We will now use an ensemble model of LightGBM, Logistic Regression and Naïve Bayes to model the same relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "84301c1f-113a-4aa0-b3d7-f6eb2ef88dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     11028\n",
      "           1       0.32      0.75      0.45      1794\n",
      "\n",
      "    accuracy                           0.74     12822\n",
      "   macro avg       0.64      0.75      0.64     12822\n",
      "weighted avg       0.86      0.74      0.78     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    class_weight='balanced',  # Automatically handles class imbalance\n",
    "    n_estimators=100,         \n",
    "    max_depth=6,              \n",
    "    learning_rate=0.1,        \n",
    "    subsample=0.8,            \n",
    "    colsample_bytree=0.8,     \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "nb = GaussianNB()\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('lgbm', lgbm), ('logreg', logreg), ('nb', nb)],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=3 \n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = stacking_model.predict(X_test_scaled)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "cf8519c3-fa21-4fd2-9134-21876c803b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Parameters: {'final_estimator__C': 10, 'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 6, 'lgbm__n_estimators': 150}\n",
      "Best Score: 0.8111193862210401\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84     11028\n",
      "           1       0.33      0.73      0.45      1794\n",
      "\n",
      "    accuracy                           0.75     12822\n",
      "   macro avg       0.64      0.74      0.65     12822\n",
      "weighted avg       0.86      0.75      0.78     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'lgbm__n_estimators': [100, 150],       \n",
    "    'lgbm__max_depth': [4, 6],             \n",
    "    'lgbm__learning_rate': [0.05, 0.1],    \n",
    "    'final_estimator__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=stacking_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1', \n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "c3b6dc29-63f4-4bfc-a859-26e7d3fc8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.66      0.78     11028\n",
      "           1       0.28      0.84      0.42      1794\n",
      "\n",
      "    accuracy                           0.68     12822\n",
      "   macro avg       0.62      0.75      0.60     12822\n",
      "weighted avg       0.87      0.68      0.73     12822\n",
      "\n",
      "Threshold: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81     11028\n",
      "           1       0.30      0.78      0.44      1794\n",
      "\n",
      "    accuracy                           0.72     12822\n",
      "   macro avg       0.63      0.75      0.63     12822\n",
      "weighted avg       0.86      0.72      0.76     12822\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84     11028\n",
      "           1       0.33      0.73      0.45      1794\n",
      "\n",
      "    accuracy                           0.75     12822\n",
      "   macro avg       0.64      0.74      0.65     12822\n",
      "weighted avg       0.86      0.75      0.78     12822\n",
      "\n",
      "Threshold: 0.6000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     11028\n",
      "           1       0.38      0.64      0.48      1794\n",
      "\n",
      "    accuracy                           0.80     12822\n",
      "   macro avg       0.66      0.74      0.68     12822\n",
      "weighted avg       0.86      0.80      0.82     12822\n",
      "\n",
      "Threshold: 0.7000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90     11028\n",
      "           1       0.43      0.58      0.49      1794\n",
      "\n",
      "    accuracy                           0.83     12822\n",
      "   macro avg       0.68      0.73      0.70     12822\n",
      "weighted avg       0.86      0.83      0.84     12822\n",
      "\n",
      "Threshold: 0.8000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     11028\n",
      "           1       0.51      0.46      0.48      1794\n",
      "\n",
      "    accuracy                           0.86     12822\n",
      "   macro avg       0.71      0.69      0.70     12822\n",
      "weighted avg       0.86      0.86      0.86     12822\n",
      "\n",
      "Threshold: 0.9000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     11028\n",
      "           1       0.68      0.26      0.37      1794\n",
      "\n",
      "    accuracy                           0.88     12822\n",
      "   macro avg       0.79      0.62      0.65     12822\n",
      "weighted avg       0.86      0.88      0.85     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for threshold tuning\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.3, 0.9, 0.1):\n",
    "    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "fd8a845d-47fd-40d8-8f1b-2b0a9aa4fcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (review_length, mentions_difficulty): 0.3980\n",
      "Correlation (sentiment_score, mentions_difficulty): 0.1132\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "corr_length, _ = pointbiserialr(df['review_length'], df['mentions_difficulty'])\n",
    "corr_sentiment, _ = pointbiserialr(df['sentiment_score'], df['mentions_difficulty'])\n",
    "\n",
    "print(f\"Correlation (review_length, mentions_difficulty): {corr_length:.4f}\")\n",
    "print(f\"Correlation (sentiment_score, mentions_difficulty): {corr_sentiment:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13281c-dbc6-4f2b-9ef5-a4bb452b5bbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7279b-fd9d-41fa-b341-8fec76304873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "233a9e3d-dd68-4c6e-84c3-79061300a2ba",
   "metadata": {},
   "source": [
    "Next, we would try to model the relationship between the genres of the game in the review and if it mentions difficulty or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0844ea7-25a9-4b2d-87ef-d87a28cbafda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['game_name', 'review', 'voted_up', 'timestamp_created',\n",
       "       'author_num_games_owned', 'author_num_reviews',\n",
       "       'author_playtime_at_review', 'author_playtime_last_two_weeks',\n",
       "       'author_playtime_forever', 'review_length', 'difficulty_word_count',\n",
       "       'mentions_difficulty', 'roguelike', 'co_op', 'base_building',\n",
       "       'soulslike', 'deckbuilding', 'puzzle', 'metroidvania', 'rpg',\n",
       "       'competitive', 'first_person', 'crpg', 'multiplayer', 'action',\n",
       "       'sandbox', 'fantasy', 'simulation', 'platformer', 'shooter',\n",
       "       'open_world', 'strategy', 'survival', 'adventure', 'crafting',\n",
       "       'third_person', 'turn_based', '2d', 'experience_level_experienced',\n",
       "       'experience_level_intermediate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f49b4fec-adbd-4c8e-84a2-792fe7aa2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the list of genre columns\n",
    "genre_columns=['roguelike', 'co_op', 'base_building',\n",
    "       'soulslike', 'deckbuilding', 'puzzle', 'metroidvania', 'rpg',\n",
    "       'competitive', 'first_person', 'crpg', 'multiplayer', 'action',\n",
    "       'sandbox', 'fantasy', 'simulation', 'platformer', 'shooter',\n",
    "       'open_world', 'strategy', 'survival', 'adventure', 'crafting',\n",
    "       'third_person', 'turn_based', '2d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebc3c37e-5079-4091-9701-619da1ed04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all the genre columns as input and mentions_difficulty as output\n",
    "X=df[genre_columns]\n",
    "y=df[\"mentions_difficulty\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "674c87ca-9d66-4478-b18c-6344ffc1d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the classes by oversampling\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a54bd229-b9e1-4f28-b892-3735d8ca8c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a decision tree classifier model\n",
    "model = DecisionTreeClassifier(\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf2e65b4-808c-4b58-879f-46f50b7fe745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a187872-0c23-43c5-bc22-1769049ec871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best F1-Score: 0.605562997308152\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],    \n",
    "    'max_depth': [5, 10, 15, None],         \n",
    "    'min_samples_split': [2, 5, 10],        \n",
    "    'min_samples_leaf': [1, 5],         \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,                   \n",
    "    verbose=2,\n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "840a492a-a920-41fa-a2e1-7fb952532ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# then we move to a random forest classifier to try to improve this\n",
    "model = RandomForestClassifier(\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e20698eb-b300-4950-b027-3e55f787ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best F1-Score: 0.6070320394187442\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we try to tune the hyperparameters again\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],          \n",
    "    'max_depth': [5, 10, None],         \n",
    "    'min_samples_split': [2, 5, 10],     \n",
    "    'min_samples_leaf': [1, 5],         \n",
    "    'max_features': ['sqrt', 'log2']     \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,                   \n",
    "    verbose=2,\n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a44847f-306c-4e56-8a32-6a1b147dc374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we now use a logistic regression model for the same relationship\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf1591e6-b5ed-4f11-a25d-9a9f6b053a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best F1-Score: 0.6070320394187442\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     11030\n",
      "           1       0.19      0.65      0.30      1792\n",
      "\n",
      "    accuracy                           0.57     12822\n",
      "   macro avg       0.55      0.60      0.49     12822\n",
      "weighted avg       0.81      0.57      0.64     12822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try to tune this model\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  \n",
    "    'penalty': ['l1', 'l2'],       \n",
    "    'solver': ['liblinear', 'saga'],  \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,                   \n",
    "    verbose=2,\n",
    "    n_jobs=-1               \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Classification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9989d-e943-4172-8fd1-834df045e7b0",
   "metadata": {},
   "source": [
    "Since it produces nearly identical results with all three models, even after tuning, we can conclude that there isn't strong enough evidence in the data to model the mentioned relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380722fb-6cd3-4498-8c27-6f8fbba0a522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
